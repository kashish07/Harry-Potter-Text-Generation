{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text generation lstm",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3Z0vqXt2EL2"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39OQJbpBvoYA"
      },
      "source": [
        "def read_text(path):\n",
        "  with open(path) as f:\n",
        "    text = f.read()\n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-iMVZKywk_d"
      },
      "source": [
        "def sep_punc(text):\n",
        "  toks = []\n",
        "  for token in nlp(text):\n",
        "    if token.text not in '\\n\\n\\n!\"#$%&()*+,-./:;<  --=>?@[\\\\]^_`{|}~\\t\\n':\n",
        "      toks.append(token.text.lower())   \n",
        "  return toks   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usT3Ru87xk6o"
      },
      "source": [
        "import spacy \n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTI0njyCxNmY"
      },
      "source": [
        "# path = \"/content/moby_dick_four_chapters.txt\"\n",
        "path = '/content/hp p1.txt'\n",
        "file_text = read_text(path)\n",
        "tokens = sep_punc(file_text)\n",
        "# print(tokens )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZguvxUhxiOX"
      },
      "source": [
        "train_len = 40 + 1\n",
        "text_sequences = []\n",
        "for i in range(train_len , len(tokens)):\n",
        "  seq = tokens[i - train_len : i]\n",
        "  text_sequences.append(seq)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCS1ot_EzwmS"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer(filters = '\\n\\n\\n!\"#$%&()*+,-./:;<  --=>?@[\\\\]^_`{|}~\\t\\n')\n",
        "tokenizer.fit_on_texts(text_sequences)\n",
        "sequences = tokenizer.texts_to_sequences(text_sequences)\n",
        "# print(sequences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYOqTaLR0zju"
      },
      "source": [
        "ind_word = tokenizer.index_word"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mWyaA-K1Hni",
        "outputId": "48983f01-7273-46fa-a827-a79813f821c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vocab_size = len(tokenizer.word_counts)\n",
        "vocab_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5860"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baY04vrz1YCC",
        "outputId": "f0884dcc-eb76-4598-cb4b-760d6b588dcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "sequences = np.array(sequences)\n",
        "X = sequences[: , :-1]\n",
        "y = sequences[: , -1]\n",
        "y = to_categorical(y , num_classes = vocab_size + 1) # + 1 for holding zeroth class\n",
        "\n",
        "seq_len = X.shape[1]\n",
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(81197, 40)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6JT0knb3ymc"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense , Embedding , LSTM , Dropout"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufV1kHPV2BXI"
      },
      "source": [
        "def create_model(vocab_size , seq_len):\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(input_dim = vocab_size , output_dim= seq_len * 2, input_length = seq_len))\n",
        "  model.add(LSTM(units= seq_len * 2 , return_sequences= True))\n",
        "  model.add(LSTM(units = seq_len*2))\n",
        "  model.add(Dense(seq_len*3 , activation = 'relu'))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(vocab_size , activation = 'softmax'))\n",
        "  model.compile(loss = 'categorical_crossentropy' , optimizer = 'adam', metrics = ['accuracy'])\n",
        "  model.summary()\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJqtuVlB3XVf",
        "outputId": "905b7982-8ef2-49a0-e9a5-e00385af3222",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = create_model(vocab_size + 1 , seq_len)\n",
        "model.fit(X, y , batch_size = 256 , epochs = 100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 40, 80)            468880    \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 40, 80)            51520     \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 80)                51520     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 120)               9720      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 120)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 5861)              709181    \n",
            "=================================================================\n",
            "Total params: 1,290,821\n",
            "Trainable params: 1,290,821\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "318/318 [==============================] - 15s 47ms/step - loss: 6.6925 - accuracy: 0.0425\n",
            "Epoch 2/100\n",
            "318/318 [==============================] - 15s 47ms/step - loss: 6.3519 - accuracy: 0.0450\n",
            "Epoch 3/100\n",
            "318/318 [==============================] - 15s 46ms/step - loss: 6.1931 - accuracy: 0.0489\n",
            "Epoch 4/100\n",
            "318/318 [==============================] - 15s 46ms/step - loss: 6.0539 - accuracy: 0.0610\n",
            "Epoch 5/100\n",
            "318/318 [==============================] - 15s 46ms/step - loss: 5.9280 - accuracy: 0.0718\n",
            "Epoch 6/100\n",
            "318/318 [==============================] - 15s 46ms/step - loss: 5.8132 - accuracy: 0.0811\n",
            "Epoch 7/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 5.7067 - accuracy: 0.0920\n",
            "Epoch 8/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 5.6086 - accuracy: 0.0996\n",
            "Epoch 9/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 5.5235 - accuracy: 0.1054\n",
            "Epoch 10/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 5.4431 - accuracy: 0.1102\n",
            "Epoch 11/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 5.3732 - accuracy: 0.1141\n",
            "Epoch 12/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 5.3069 - accuracy: 0.1178\n",
            "Epoch 13/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 5.2479 - accuracy: 0.1209\n",
            "Epoch 14/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 5.1839 - accuracy: 0.1250\n",
            "Epoch 15/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 5.1295 - accuracy: 0.1269\n",
            "Epoch 16/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 5.0719 - accuracy: 0.1313\n",
            "Epoch 17/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 5.0132 - accuracy: 0.1336\n",
            "Epoch 18/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 4.9588 - accuracy: 0.1355\n",
            "Epoch 19/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 4.9080 - accuracy: 0.1388\n",
            "Epoch 20/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 4.8563 - accuracy: 0.1413\n",
            "Epoch 21/100\n",
            "318/318 [==============================] - 15s 46ms/step - loss: 4.8056 - accuracy: 0.1437\n",
            "Epoch 22/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 4.7559 - accuracy: 0.1464\n",
            "Epoch 23/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 4.7108 - accuracy: 0.1493\n",
            "Epoch 24/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 4.6649 - accuracy: 0.1507\n",
            "Epoch 25/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 4.6204 - accuracy: 0.1533\n",
            "Epoch 26/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 4.5764 - accuracy: 0.1534\n",
            "Epoch 27/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 4.5350 - accuracy: 0.1581\n",
            "Epoch 28/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 4.4951 - accuracy: 0.1597\n",
            "Epoch 29/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 4.4574 - accuracy: 0.1628\n",
            "Epoch 30/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 4.4210 - accuracy: 0.1654\n",
            "Epoch 31/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 4.3821 - accuracy: 0.1665\n",
            "Epoch 32/100\n",
            "318/318 [==============================] - 14s 46ms/step - loss: 4.3432 - accuracy: 0.1694\n",
            "Epoch 33/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 4.3153 - accuracy: 0.1718\n",
            "Epoch 34/100\n",
            "318/318 [==============================] - 14s 46ms/step - loss: 4.2804 - accuracy: 0.1748\n",
            "Epoch 35/100\n",
            "318/318 [==============================] - 15s 46ms/step - loss: 4.2476 - accuracy: 0.1763\n",
            "Epoch 36/100\n",
            "318/318 [==============================] - 15s 46ms/step - loss: 4.2146 - accuracy: 0.1790\n",
            "Epoch 37/100\n",
            "318/318 [==============================] - 15s 46ms/step - loss: 4.1861 - accuracy: 0.1817\n",
            "Epoch 38/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 4.1531 - accuracy: 0.1860\n",
            "Epoch 39/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 4.1276 - accuracy: 0.1890\n",
            "Epoch 40/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 4.0960 - accuracy: 0.1917\n",
            "Epoch 41/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 4.0711 - accuracy: 0.1931\n",
            "Epoch 42/100\n",
            "318/318 [==============================] - 15s 46ms/step - loss: 4.0485 - accuracy: 0.1952\n",
            "Epoch 43/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 4.0190 - accuracy: 0.1992\n",
            "Epoch 44/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 3.9946 - accuracy: 0.1996\n",
            "Epoch 45/100\n",
            "318/318 [==============================] - 14s 46ms/step - loss: 3.9715 - accuracy: 0.2033\n",
            "Epoch 46/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 3.9502 - accuracy: 0.2066\n",
            "Epoch 47/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 3.9263 - accuracy: 0.2073\n",
            "Epoch 48/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 3.9050 - accuracy: 0.2094\n",
            "Epoch 49/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 3.8849 - accuracy: 0.2136\n",
            "Epoch 50/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 3.8642 - accuracy: 0.2156\n",
            "Epoch 51/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 3.8421 - accuracy: 0.2174\n",
            "Epoch 52/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 3.8233 - accuracy: 0.2201\n",
            "Epoch 53/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 3.8010 - accuracy: 0.2205\n",
            "Epoch 54/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 3.7840 - accuracy: 0.2238\n",
            "Epoch 55/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 3.7661 - accuracy: 0.2259\n",
            "Epoch 56/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 3.7457 - accuracy: 0.2279\n",
            "Epoch 57/100\n",
            "318/318 [==============================] - 14s 44ms/step - loss: 3.7310 - accuracy: 0.2305\n",
            "Epoch 58/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 3.7082 - accuracy: 0.2329\n",
            "Epoch 59/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 3.6922 - accuracy: 0.2356\n",
            "Epoch 60/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 3.6759 - accuracy: 0.2373\n",
            "Epoch 61/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 3.6593 - accuracy: 0.2383\n",
            "Epoch 62/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 3.6415 - accuracy: 0.2406\n",
            "Epoch 63/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 3.6243 - accuracy: 0.2431\n",
            "Epoch 64/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 3.6105 - accuracy: 0.2447\n",
            "Epoch 65/100\n",
            "318/318 [==============================] - 14s 44ms/step - loss: 3.5970 - accuracy: 0.2460\n",
            "Epoch 66/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 3.5798 - accuracy: 0.2473\n",
            "Epoch 67/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 3.5629 - accuracy: 0.2511\n",
            "Epoch 68/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 3.5464 - accuracy: 0.2529\n",
            "Epoch 69/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 3.5354 - accuracy: 0.2548\n",
            "Epoch 70/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 3.5196 - accuracy: 0.2570\n",
            "Epoch 71/100\n",
            "318/318 [==============================] - 14s 44ms/step - loss: 3.5042 - accuracy: 0.2572\n",
            "Epoch 72/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 3.4937 - accuracy: 0.2600\n",
            "Epoch 73/100\n",
            "318/318 [==============================] - 14s 44ms/step - loss: 3.4732 - accuracy: 0.2615\n",
            "Epoch 74/100\n",
            "318/318 [==============================] - 14s 44ms/step - loss: 3.4618 - accuracy: 0.2628\n",
            "Epoch 75/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 3.4483 - accuracy: 0.2651\n",
            "Epoch 76/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 3.4336 - accuracy: 0.2686\n",
            "Epoch 77/100\n",
            "318/318 [==============================] - 14s 44ms/step - loss: 3.4224 - accuracy: 0.2678\n",
            "Epoch 78/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 3.4095 - accuracy: 0.2699\n",
            "Epoch 79/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 3.3944 - accuracy: 0.2724\n",
            "Epoch 80/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 3.3819 - accuracy: 0.2736\n",
            "Epoch 81/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 3.3646 - accuracy: 0.2766\n",
            "Epoch 82/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 3.3561 - accuracy: 0.2770\n",
            "Epoch 83/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 3.3435 - accuracy: 0.2784\n",
            "Epoch 84/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 3.3334 - accuracy: 0.2816\n",
            "Epoch 85/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 3.3162 - accuracy: 0.2826\n",
            "Epoch 86/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 3.3048 - accuracy: 0.2837\n",
            "Epoch 87/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 3.2901 - accuracy: 0.2858\n",
            "Epoch 88/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 3.2748 - accuracy: 0.2873\n",
            "Epoch 89/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 3.2657 - accuracy: 0.2890\n",
            "Epoch 90/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 3.2516 - accuracy: 0.2913\n",
            "Epoch 91/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 3.2432 - accuracy: 0.2923\n",
            "Epoch 92/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 3.2323 - accuracy: 0.2928\n",
            "Epoch 93/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 3.2146 - accuracy: 0.2950\n",
            "Epoch 94/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 3.2056 - accuracy: 0.2977\n",
            "Epoch 95/100\n",
            "318/318 [==============================] - 14s 44ms/step - loss: 3.1958 - accuracy: 0.2981\n",
            "Epoch 96/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 3.1868 - accuracy: 0.2998\n",
            "Epoch 97/100\n",
            "318/318 [==============================] - 14s 44ms/step - loss: 3.1724 - accuracy: 0.3003\n",
            "Epoch 98/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 3.1586 - accuracy: 0.3035\n",
            "Epoch 99/100\n",
            "318/318 [==============================] - 14s 44ms/step - loss: 3.1495 - accuracy: 0.3071\n",
            "Epoch 100/100\n",
            "318/318 [==============================] - 14s 45ms/step - loss: 3.1372 - accuracy: 0.3072\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd26bb9b780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Lo7z7gYi6r0"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "def generate_text(model , tokenizer , seq_len , seed_text, no_of_words):\n",
        "  output_text = []\n",
        "  input_text = seed_text\n",
        "\n",
        "  for i in range(no_of_words):\n",
        "    encoded_text = tokenizer.texts_to_sequences([input_text])[0]\n",
        "    pad_encoded = pad_sequences([encoded_text] , maxlen = seq_len , truncating = 'pre')\n",
        "\n",
        "    ind = np.argmax(model.predict(pad_encoded) , axis = 1)[0]\n",
        "    # type(ind)\n",
        "    word = tokenizer.index_word[ind]\n",
        "    input_text += ' ' + word\n",
        "\n",
        "    output_text.append(word)\n",
        "\n",
        "  return ' '.join(output_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ufmp-yjBkh8X",
        "outputId": "0302799e-e765-48fe-bc23-cee48a4ceed4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import random\n",
        "r_p = random.randint(0 , len(text_sequences))\n",
        "rand_text = text_sequences[r_p]\n",
        "seed_text = ' '.join(rand_text)\n",
        "\n",
        "# seed_text\n",
        "new = generate_text(model , tokenizer ,seq_len , seed_text , 40)\n",
        "# print(seed_text + \"\\n\" + new )\n",
        "seed_text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"the zoo director himself made aunt petunia a cup of strong sweet tea while he apologized over and over again piers and dudley could only gibber as far as harry had seen the snake had n't done anything except snap playfully\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LB0BEq5hzkHu",
        "outputId": "e15aac9c-a89a-4092-cc18-dcc81a8ec217",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# seed_text = 'harry did not wanted to join the slytherine he knew about people who were particularly bad and belonged to slytherine'\n",
        "generate_text(model , tokenizer , seq_len , seed_text , 40)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"at their heels as it was a very good mood in the door i 'm not going to be fair to be able to breathe though he was n't sure he was n't sure he was n't sure he was\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EfcXySAN5zz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}